<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>反卷积与棋盘效应 | PommesPeter&#39;s Blog</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/imgs/favicon.ico">
    <meta name="description" content="PommesPeter Knowledge Base">
    <meta name="keywords" content="深度学习,科研,技术,算法,课程学习">
    <meta name="theme-color" content="#11a8cd">
    <link rel="preload" href="/assets/css/0.styles.3f342bf6.css" as="style"><link rel="preload" href="/assets/js/app.b6cd2856.js" as="script"><link rel="preload" href="/assets/js/6.046822e7.js" as="script"><link rel="preload" href="/assets/js/7.732bae66.js" as="script"><link rel="preload" href="/assets/js/8.8f95e629.js" as="script"><link rel="prefetch" href="/assets/js/10.0902abd0.js"><link rel="prefetch" href="/assets/js/11.3c915858.js"><link rel="prefetch" href="/assets/js/12.f3e1e315.js"><link rel="prefetch" href="/assets/js/13.e2350660.js"><link rel="prefetch" href="/assets/js/14.5e2fd461.js"><link rel="prefetch" href="/assets/js/15.cd5686b4.js"><link rel="prefetch" href="/assets/js/16.29f23c7f.js"><link rel="prefetch" href="/assets/js/17.64ec132e.js"><link rel="prefetch" href="/assets/js/18.8212c930.js"><link rel="prefetch" href="/assets/js/19.c1fc03db.js"><link rel="prefetch" href="/assets/js/20.f5123af2.js"><link rel="prefetch" href="/assets/js/21.8ff84a71.js"><link rel="prefetch" href="/assets/js/22.38dc50ca.js"><link rel="prefetch" href="/assets/js/23.afdefdbc.js"><link rel="prefetch" href="/assets/js/24.c2e6439d.js"><link rel="prefetch" href="/assets/js/25.ee4c646f.js"><link rel="prefetch" href="/assets/js/26.387f677d.js"><link rel="prefetch" href="/assets/js/27.469785b0.js"><link rel="prefetch" href="/assets/js/28.c4f78f5c.js"><link rel="prefetch" href="/assets/js/29.86512608.js"><link rel="prefetch" href="/assets/js/30.a7ceb7ad.js"><link rel="prefetch" href="/assets/js/31.0815fd03.js"><link rel="prefetch" href="/assets/js/32.5000ae58.js"><link rel="prefetch" href="/assets/js/33.c5cb558c.js"><link rel="prefetch" href="/assets/js/34.8fdf2be6.js"><link rel="prefetch" href="/assets/js/35.eb4cab8e.js"><link rel="prefetch" href="/assets/js/36.37865d94.js"><link rel="prefetch" href="/assets/js/37.85c78b4e.js"><link rel="prefetch" href="/assets/js/38.c40fcc2f.js"><link rel="prefetch" href="/assets/js/39.e5d3114c.js"><link rel="prefetch" href="/assets/js/40.c830bf37.js"><link rel="prefetch" href="/assets/js/41.b5b22557.js"><link rel="prefetch" href="/assets/js/42.b4d72e3e.js"><link rel="prefetch" href="/assets/js/43.51ba43e8.js"><link rel="prefetch" href="/assets/js/44.cd10149e.js"><link rel="prefetch" href="/assets/js/45.84a75a30.js"><link rel="prefetch" href="/assets/js/46.a6000d66.js"><link rel="prefetch" href="/assets/js/47.fe1c37c4.js"><link rel="prefetch" href="/assets/js/48.a776bba4.js"><link rel="prefetch" href="/assets/js/49.2854881f.js"><link rel="prefetch" href="/assets/js/50.6091fed2.js"><link rel="prefetch" href="/assets/js/51.7beb1e40.js"><link rel="prefetch" href="/assets/js/52.4f244ef7.js"><link rel="prefetch" href="/assets/js/53.e478e38b.js"><link rel="prefetch" href="/assets/js/54.0293cde8.js"><link rel="prefetch" href="/assets/js/55.e9e4288d.js"><link rel="prefetch" href="/assets/js/56.33674328.js"><link rel="prefetch" href="/assets/js/9.e2c2f23d.js"><link rel="prefetch" href="/assets/js/mermaid.bb411913.js"><link rel="prefetch" href="/assets/js/vendors~flowchart.10d14a57.js"><link rel="prefetch" href="/assets/js/vendors~mermaid.3841498c.js"><link rel="prefetch" href="/assets/js/vendors~reveal.c552e7bc.js">
    <link rel="stylesheet" href="/assets/css/0.styles.3f342bf6.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu have-body-img"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">PommesPeter's Blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">酷炫主页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="✨深度学习" class="dropdown-title"><a href="/deeplearning/" class="link-title router-link-active">✨深度学习</a> <span class="title" style="display:none;">✨深度学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/deeplearning/rearch/howtoreadpaper.html" class="nav-link">科研方法</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/basisframework.html" class="nav-link">深度学习导论</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/imageclassification.html" class="nav-link">图像分类</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/objectdetection.html" class="nav-link">目标检测</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/semanticsegmentation.html" class="nav-link">图像分割</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/lowlightenhancement.html" class="nav-link">低照度增强</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🎉算法" class="dropdown-title"><a href="/algorithm/" class="link-title">🎉算法</a> <span class="title" style="display:none;">🎉算法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/algorithm/basis.html" class="nav-link">算法基础思想</a></li><li class="dropdown-item"><!----> <a href="/algorithm/basisframework.html" class="nav-link">刷题记录</a></li><li class="dropdown-item"><!----> <a href="/algorithm/imageclassification.html" class="nav-link">奇怪的算法记录</a></li><li class="dropdown-item"><!----> <a href="/algorithm/objectdetection.html" class="nav-link">杂项笔记</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="👀开发技术" class="dropdown-title"><a href="/development/" class="link-title">👀开发技术</a> <span class="title" style="display:none;">👀开发技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/development/basis.html" class="nav-link">前端开发</a></li><li class="dropdown-item"><!----> <a href="/development/basisframework.html" class="nav-link">后端开发</a></li><li class="dropdown-item"><!----> <a href="/development/git.html" class="nav-link">Git版本控制</a></li><li class="dropdown-item"><!----> <a href="/development/objectdetection.html" class="nav-link">杂项笔记</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="😊课程学习" class="dropdown-title"><a href="/courses/" class="link-title">😊课程学习</a> <span class="title" style="display:none;">😊课程学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/courses/oop/class/" class="nav-link">面向对象程序设计</a></li><li class="dropdown-item"><!----> <a href="/courses/mathmodeling/linear/" class="nav-link">数学建模</a></li><li class="dropdown-item"><!----> <a href="/courses/database/concept/" class="nav-link">数据库系统概论</a></li><li class="dropdown-item"><!----> <a href="/courses/algorithm/coucept.html" class="nav-link">算法设计与分析</a></li><li class="dropdown-item"><!----> <a href="/courses/69521d/" class="nav-link">数字图像处理</a></li><li class="dropdown-item"><!----> <a href="/courses/527279/" class="nav-link">软件工程与UML</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🐧Linux" class="dropdown-title"><a href="/linux/" class="link-title">🐧Linux</a> <span class="title" style="display:none;">🐧Linux</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/linux/memo/" class="nav-link">备忘录</a></li><li class="dropdown-item"><!----> <a href="/linuxsolution/" class="nav-link">问题解决方案</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🤷‍♂️更多" class="dropdown-title"><a href="/about/" class="link-title">🤷‍♂️更多</a> <span class="title" style="display:none;">🤷‍♂️更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/about/" class="nav-link">关于</a></li><li class="dropdown-item"><!----> <a href="/mindmap/" class="nav-link">思维</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友链</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🌹索引" class="dropdown-title"><a href="/archives/" class="link-title">🌹索引</a> <span class="title" style="display:none;">🌹索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/PommesPeter/MemoSummary" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/imgs/mytx.png"> <div class="blogger-info"><h3>PommesPeter</h3> <span>深度炼丹师</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">酷炫主页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="✨深度学习" class="dropdown-title"><a href="/deeplearning/" class="link-title router-link-active">✨深度学习</a> <span class="title" style="display:none;">✨深度学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/deeplearning/rearch/howtoreadpaper.html" class="nav-link">科研方法</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/basisframework.html" class="nav-link">深度学习导论</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/imageclassification.html" class="nav-link">图像分类</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/objectdetection.html" class="nav-link">目标检测</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/semanticsegmentation.html" class="nav-link">图像分割</a></li><li class="dropdown-item"><!----> <a href="/deeplearning/lowlightenhancement.html" class="nav-link">低照度增强</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🎉算法" class="dropdown-title"><a href="/algorithm/" class="link-title">🎉算法</a> <span class="title" style="display:none;">🎉算法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/algorithm/basis.html" class="nav-link">算法基础思想</a></li><li class="dropdown-item"><!----> <a href="/algorithm/basisframework.html" class="nav-link">刷题记录</a></li><li class="dropdown-item"><!----> <a href="/algorithm/imageclassification.html" class="nav-link">奇怪的算法记录</a></li><li class="dropdown-item"><!----> <a href="/algorithm/objectdetection.html" class="nav-link">杂项笔记</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="👀开发技术" class="dropdown-title"><a href="/development/" class="link-title">👀开发技术</a> <span class="title" style="display:none;">👀开发技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/development/basis.html" class="nav-link">前端开发</a></li><li class="dropdown-item"><!----> <a href="/development/basisframework.html" class="nav-link">后端开发</a></li><li class="dropdown-item"><!----> <a href="/development/git.html" class="nav-link">Git版本控制</a></li><li class="dropdown-item"><!----> <a href="/development/objectdetection.html" class="nav-link">杂项笔记</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="😊课程学习" class="dropdown-title"><a href="/courses/" class="link-title">😊课程学习</a> <span class="title" style="display:none;">😊课程学习</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/courses/oop/class/" class="nav-link">面向对象程序设计</a></li><li class="dropdown-item"><!----> <a href="/courses/mathmodeling/linear/" class="nav-link">数学建模</a></li><li class="dropdown-item"><!----> <a href="/courses/database/concept/" class="nav-link">数据库系统概论</a></li><li class="dropdown-item"><!----> <a href="/courses/algorithm/coucept.html" class="nav-link">算法设计与分析</a></li><li class="dropdown-item"><!----> <a href="/courses/69521d/" class="nav-link">数字图像处理</a></li><li class="dropdown-item"><!----> <a href="/courses/527279/" class="nav-link">软件工程与UML</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🐧Linux" class="dropdown-title"><a href="/linux/" class="link-title">🐧Linux</a> <span class="title" style="display:none;">🐧Linux</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/linux/memo/" class="nav-link">备忘录</a></li><li class="dropdown-item"><!----> <a href="/linuxsolution/" class="nav-link">问题解决方案</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🤷‍♂️更多" class="dropdown-title"><a href="/about/" class="link-title">🤷‍♂️更多</a> <span class="title" style="display:none;">🤷‍♂️更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/about/" class="nav-link">关于</a></li><li class="dropdown-item"><!----> <a href="/mindmap/" class="nav-link">思维</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友链</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="🌹索引" class="dropdown-title"><a href="/archives/" class="link-title">🌹索引</a> <span class="title" style="display:none;">🌹索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/PommesPeter/MemoSummary" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>科研方法</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>深度学习导论</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>YOLOv5</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>神经网络杂项</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/deeplearning/dlother/deconvandcheckerboard/" aria-current="page" class="active sidebar-link">反卷积与棋盘效应</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#抛出问题" class="sidebar-link">抛出问题</a></li><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#deconvolution和overlap" class="sidebar-link">Deconvolution和Overlap</a></li><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#overlap和learning" class="sidebar-link">Overlap和Learning</a></li><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#better-upsampling" class="sidebar-link">Better Upsampling</a></li><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#implement" class="sidebar-link">Implement</a></li><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#image-generation-results" class="sidebar-link">Image Generation Results</a></li><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#artifacts-in-gradients" class="sidebar-link">Artifacts in Gradients</a></li><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#conclusion" class="sidebar-link">Conclusion</a></li><li class="sidebar-sub-header"><a href="/deeplearning/dlother/deconvandcheckerboard/#reference" class="sidebar-link">Reference</a></li></ul></li></ul></section></li></ul> </aside> <div><main class="page"> <div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-f5f35434><div class="articleInfo" data-v-f5f35434><ul class="breadcrumbs" data-v-f5f35434><li data-v-f5f35434><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-f5f35434></a></li> <li data-v-f5f35434><a href="/deeplearning" title="DeepLearning-目录页" class="router-link-active" data-v-f5f35434>DeepLearning</a></li> <li data-v-f5f35434><a href="/deeplearning/#神经网络杂项" title="DeepLearning#神经网络杂项" data-v-f5f35434>神经网络杂项</a></li></ul> <div class="info" data-v-f5f35434><div title="作者" class="author iconfont icon-touxiang" data-v-f5f35434><a href="https://github.com/PommesPeter" target="_blank" title="作者" class="beLink" data-v-f5f35434>PommesPeter</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-f5f35434><a href="javascript:;" data-v-f5f35434>2021-08-28</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">
          反卷积与棋盘效应
        </h1> <div class="theme-vdoing-content content__default"><h1 id="deconvolution-and-checkerboard-artifacts"><a href="#deconvolution-and-checkerboard-artifacts" class="header-anchor">#</a> Deconvolution and Checkerboard Artifacts</h1> <p>Augustus Odena，<a href="http://vdumoulin.github.io/" target="_blank" rel="noopener noreferrer">Vincent Dumoulin<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，<a href="http://colah.github.io/" target="_blank" rel="noopener noreferrer">Chris Olah<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="抛出问题"><a href="#抛出问题" class="header-anchor">#</a> 抛出问题</h2> <p><img src="/assets/img/image-20210827114052890.e38ca46c.png" alt="image-20210827114052890"></p> <p>我们可以看到上面这几张图片，仔细看能够明显看到有一些奇怪的类似棋盘格子的图案，这是一个在使用Convolution的时候经常会遇到的问题。我们可以称为棋盘效应(checkerboard pattern of artifacts)。一般来说，棋盘效应会在颜色比较明显、鲜艳，丰富的图片上最为明显，到底发生了什么才导致这样的结果？是神经网络更喜欢明亮一点的颜色？产生这些伪影的原因实际上非常简单，下面将讲解其原理和解决方法。</p> <h2 id="deconvolution和overlap"><a href="#deconvolution和overlap" class="header-anchor">#</a> Deconvolution和Overlap</h2> <p>当我们用神经网络生成一些图片的时候，我们通常是用多通道低分辨率的Feature Map生成图片。这样能够使得神经网络可以先输出粗糙的图像，然后填充细节。为了实现这种操作，我们需要一种方式能够使得从低分辨率图像变成高分辨率图像。我们通常就会使用反卷积操作(Deconvolution)。通俗来讲，反卷积层主要作用是将低分辨率图像中的每一个像素映射成由多个像素组成的更大的方形。</p> <blockquote><p>反卷积有多种解释和不同的名称，包括“转置卷积”。为了简洁起见，我们在本文中使用名称“反卷积”。有关反卷积的纹线，请参见 [<a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank" rel="noopener noreferrer">5<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, <a href="https://arxiv.org/pdf/1609.07009.pdf" target="_blank" rel="noopener noreferrer">6<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]。</p></blockquote> <p>不幸的是，反卷积很容易产生“不均匀重叠”，在某些地方比其他地方放置更多的隐喻[<a href="http://www.foldl.me/uploads/papers/tr-cgans.pdf" target="_blank" rel="noopener noreferrer">7<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]。 特别是，当kernel大小（输出窗口大小）不能被stride步长（顶部点之间的间距）整除时，反卷积具有不均匀的重叠。 虽然原则上网络可以仔细学习权重来避免这种情况 ，我们将在后面更详细地讨论 。但在实践中，神经网络很难完全避免这种情况。</p> <p><img src="/assets/img/image-20210828155705611.bbda72cf.png" alt="image-20210828155705611"></p> <p><img src="/assets/img/image-20210828155724700.ea828921.png" alt="image-20210828155724700"></p> <p>重叠图案也以二维形式形成。两个轴上的不均匀重叠相乘在一起，形成了不同大小的典型棋盘状图案。</p> <p><img src="/assets/img/image-20210828155921907.6cb50000.png" alt="image-20210828155921907"></p> <p>事实上，不均匀的重叠在两个维度上往往会更加极端！ 因为这两个图案相乘，所以不均匀度会平方。 例如，在一维中，步幅为 2，大小为 3 的反卷积的某些输出的输入数量是其他的两倍，但在二维中，这变成了四倍。</p> <p>现在，神经网络通常在生成图像时使用多层反卷积，从一系列较低分辨率的描述中迭代构建更大的图像。 虽然这些堆叠的反卷积可以消除伪影，但它们通常会组合在一起，在各种尺度上产生伪影。</p> <p><img src="/assets/img/image-20210828160459764.2e052545.png" alt="image-20210828160459764"></p> <p><strong>步长为1的反卷积</strong>—我们经常将其视为成功模型中的最后一层（例如 [<a href="https://arxiv.org/pdf/1606.03498.pdf" target="_blank" rel="noopener noreferrer">2<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]）  在抑制伪影方面非常有效。 他们可以去除划分其大小的频率伪影，并减少频率小于其大小的其他伪影。 然而，正如在许多最近的模型中看到的那样，伪影仍然可以泄漏。</p> <p>除了我们在上面观察到的类似棋盘格的高频伪影之外，早期的反卷积会产生低频伪影，我们将在后面更详细地探讨这些伪影。</p> <p>当输出不寻常的颜色时，这些伪影往往最为突出。 由于神经网络层通常具有偏差（添加到输出中的学习值），因此很容易输出平均颜色。 颜色 — 像鲜红色 — 离平均颜色越远，反卷积需要做出的贡献就越大。</p> <h2 id="overlap和learning"><a href="#overlap和learning" class="header-anchor">#</a> Overlap和Learning</h2> <p>从不均匀重叠的角度考虑事情是 —— 虽然一个有用的框架——有点简单化。 无论好坏，我们的模型都会为它们的反卷积学习权重。</p> <p>理论上，我们的模型可以学习不均匀重叠的位置，从而使输出均匀平衡。</p> <p><img src="/assets/img/image-20210828170129323.3b3de072.png" alt="image-20210828170129323"></p> <p>这是一种难以实现的平衡行为，尤其是当有多个渠道交互时。 避免伪影会显着限制可能的过滤器，从而牺牲模型大小。 在实践中，神经网络应该要学习完全避免这些模式。</p> <p>事实上，不仅不均匀重叠的模型没有学会避免这种情况，甚至重叠的模型经常学习导致类似伪影的内核！ 虽然它们的默认行为不像不均匀重叠那样，但即使重叠反卷积也很容易导致伪影。</p> <p><img src="/assets/img/image-20210828170146395.975861d2.png" alt="image-20210828170146395"></p> <p>完全避免伪影仍然是对过滤器的一个重要限制，实际上这些模型中仍然存在伪影，尽管它们看起来更温和。 （参见 [<a href="https://arxiv.org/pdf/1606.00704.pdf" target="_blank" rel="noopener noreferrer">4<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]，它使用 stride 2 size 4 deconvolutions 作为示例。）</p> <p>这里可能有很多因素在起作用。 例如，在生成对抗网络 (GAN) 的情况下，一个问题可能是鉴别器及其梯度（我们将在后面详细讨论）。 但问题的很大一部分似乎是反卷积。 最好的情况是，反卷积是脆弱的，因为它很容易表示生成棋盘效应的函数，即使大小是经过仔细选择的。 在最坏的情况下，棋盘效应是反卷积的默认行为。</p> <p>是否有不同的上采样方法更能抵抗伪影？</p> <h2 id="better-upsampling"><a href="#better-upsampling" class="header-anchor">#</a> Better Upsampling</h2> <p>为了避免这些伪影，我们想要一种替代常规反卷积（“转置卷积”）的方法。 与反卷积不同，这种上采样方法不应将伪影作为其默认行为。 理想情况下，它会走得更远，并且偏向于此类工件。</p> <p>一种方法是确保使用除以步幅的内核大小，避免重叠问题。 这相当于“子像素卷积”，这是一种最近在图像超分辨率方面取得成功的技术 [<a href="https://arxiv.org/pdf/1609.05158.pdf" target="_blank" rel="noopener noreferrer">8<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]。 然而，虽然这种方法有帮助，但反卷积仍然很容易生成伪影。</p> <p>另一种方法是将上采样到更高分辨率从卷积中分离出来以计算特征。 例如，可以调整图像大小（使用<a href="https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation" target="_blank" rel="noopener noreferrer">最近邻插值<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>或<a href="https://en.wikipedia.org/wiki/Bilinear_interpolation" target="_blank" rel="noopener noreferrer">双线性插值<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>），然后使用卷积层。 这似乎是一种自然的方法，大致相似的方法在图像超分辨率方面效果很好（例如 [<a href="https://arxiv.org/pdf/1501.00092.pdf" target="_blank" rel="noopener noreferrer">9<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]）。</p> <p><img src="/assets/img/image-20210828170344536.32e4f5c1.png" alt="image-20210828170344536"></p> <p>反卷积和不同的 resize-convolution 方法都是线性运算，可以解释为矩阵。 这是查看它们之间差异的方法。 反卷积对每个输出窗口都有一个唯一的输入，resize-convolution 以一种降低高频伪影的方式隐式地进行权重绑定。</p> <p>我们使用最近邻插值获得了最好的结果，但很难使双线性插值起作用。 这可能只是意味着，对于我们的模型，最近邻恰好与为反卷积优化的超参数配合得很好。 它还可能指出简单地使用双线性插值的问题，它对高频图像特征的抵抗力过强。 我们不一定认为这两种方法都是上采样的最终解决方案，但它们确实修复了棋盘效应。</p> <h2 id="implement"><a href="#implement" class="header-anchor">#</a> Implement</h2> <p>调整大小卷积层可以使用<code>tf.image.resize_images()</code>在 TensorFlow 中轻松实现。 为获得最佳结果，请在使用 <code>tf.nn.conv2d()</code> 进行卷积之前使用 <code>tf.pad()</code>以避免边界伪影。</p> <h2 id="image-generation-results"><a href="#image-generation-results" class="header-anchor">#</a> Image Generation Results</h2> <p>我们的经验是，在各种上下文中，最近邻调整大小后进行卷积效果非常好。</p> <p>我们发现这种方法有帮助的一个例子是生成对抗网络。 简单地将标准反卷积层切换为最近邻调整大小，然后进行卷积会导致不同频率的伪影消失。</p> <p><img src="/assets/img/image-20210828170551006.5106b6d5.png" alt="image-20210828170551006"></p> <p>事实上，在任何训练发生之前就可以看到棋盘效应的差异。 如果我们查看生成器生成的图像，使用随机权重进行初始化，我们已经可以看到伪影：</p> <p><img src="/assets/img/image-20210828170609251.ac0bf084.png" alt="image-20210828170609251"></p> <p>这表明伪影是由于这种生成图像的方法所导致，而不是因为对抗性训练引入伪影。 （这也表明我们可能能够在没有训练模型缓慢反馈周期的情况下学到很多关于良好生成器设计的知识。）</p> <p>相信这些伪影不是 GAN 特有的另一个原因是我们在其他模型中也看到它们，并且发现当我们切换到resize-convolution进行上采样时它们也会消失。 例如，考虑实时艺术风格迁移 [<a href="https://arxiv.org/pdf/1603.08155.pdf" target="_blank" rel="noopener noreferrer">10<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]，其中训练神经网络以直接生成风格迁移图像。 我们发现这些很容易受到棋盘效应的影响（尤其是当损失函数没有明确抵抗它们时）。 然而，将反卷积层换成resize-convolution层时就让棋盘效应消失了。</p> <p><img src="/assets/img/image-20210828170625428.c9aafb5b.png" alt="image-20210828170625428"></p> <p>Google Brain 团队即将发表的论文将在更彻底的实验和最先进的结果中展示这种技术的好处。 （我们选择单独介绍这项技术，因为我们觉得它值得更详细的讨论，而且因为它跨越了多篇论文。）</p> <h2 id="artifacts-in-gradients"><a href="#artifacts-in-gradients" class="header-anchor">#</a> Artifacts in Gradients</h2> <p>每当我们计算卷积层的梯度时，我们都会对反向传播进行反卷积（转置卷积）。 这可能会导致渐变中出现棋盘格图案，就像我们使用反卷积生成图像时一样。</p> <p>图像模型梯度中高频“噪声”的存在在特征可视化社区中是众所周知的，这是一个重大挑战。 不知何故，特征可视化方法必须补偿这种噪音。</p> <p>例如，DeepDream [<a href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" target="_blank" rel="noopener noreferrer">11<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>] 似乎以多种方式在棋盘效应之间造成破坏性干扰，例如同时优化许多特征，以及在许多偏移和尺度上进行优化。 特别是，在不同偏移量下优化的“抖动”抵消了一些棋盘伪影。</p> <p><img src="/assets/img/image-20210828170738818.5a032548.png" alt="image-20210828170738818"></p> <blockquote><p>虽然一些伪影是我们的标准棋盘格模式，但其他人的是组织较少的高频模式。我们认为这些是由最大池化引起的。最大池化以前与 [<a href="https://arxiv.org/pdf/1511.06394.pdf" target="_blank" rel="noopener noreferrer">12<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>] 中的高频伪影相关联。</p></blockquote> <p>最近在特征可视化方面的工作（例如 [<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb" target="_blank" rel="noopener noreferrer">13<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）准确识别并补偿了这些高频梯度分量。 所以这里就提出了一个问题：更好的神经网络架构是否可以不需要使用这些技巧避免伪影的产生。</p> <p>这些梯度伪影会影响 GAN 吗？ 如果梯度伪影可以影响基于特征可视化中的神经网络梯度优化的图像，我们也可能期望它影响由生成器参数化的图像系列，因为它们被 GAN 中的鉴别器优化。</p> <p>我们发现在某些情况下确实会发生这种情况。 当生成器既不变成棋盘效应也不对抗棋盘效应时，鉴别器中的跨步卷积会导致它们。</p> <p><img src="/assets/img/image-20210828170840318.280c9a46.png" alt="image-20210828170840318"></p> <p>目前尚不清楚这些梯度伪影的更广泛影响是什么。 考虑它们的一种方法是，一些神经元会用邻近的梯度多此计算，被计算的梯度是任意选取的。 同样，网络会更关心输入中的某些像素。 这两个听起来都不理想。</p> <p>似乎有一些像素比其他像素对网络输出的影响更大可能会夸大对抗性反例。 由于导数集中在少量像素上，这些像素的微小扰动可能会产生巨大的影响。 我们没有对此进行调查。</p> <h2 id="conclusion"><a href="#conclusion" class="header-anchor">#</a> Conclusion</h2> <p>使用反卷积生成图像的标准方法 — 尽管它取得了成功！ 存在一些概念上简单的问题，这些问题会导致生成的图像出现伪影。 使用没有这些问题的自然替代方法会导致伪影消失（类似的论点表明标准跨步卷积层也可能存在问题）。</p> <p>这对我们来说似乎是一个令人兴奋的机会！ 它表明，仔细思考神经网络架构，即使在我们似乎有明确的工作解决方案的情况下，也可以找到容易实现的成果。</p> <p>与此同时，我们提供了一个易于使用的解决方案，可以提高许多使用神经网络生成图像的方法的质量。 我们期待看到人们用它做什么，以及它是否在音频等领域有所帮助，在这些领域，高频伪影尤其成问题。</p> <h2 id="reference"><a href="#reference" class="header-anchor">#</a> Reference</h2> <ol><li><strong>Unsupervised representation learning with deep convolutional generative adversarial networks</strong> <a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Radford, A., Metz, L. and Chintala, S., 2015. arXiv preprint arXiv:1511.06434.</li> <li><strong>Improved techniques for training gans</strong> <a href="https://arxiv.org/pdf/1606.03498.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A. and Chen, X., 2016. Advances in Neural Information Processing Systems, pp. 2226—2234.</li> <li><strong>Adversarial Feature Learning</strong> <a href="https://arxiv.org/pdf/1605.09782.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Donahue, J., Krahenbuhl, P. and Darrell, T., 2016. arXiv preprint arXiv:1605.09782.</li> <li><strong>Adversarially Learned Inference</strong> <a href="https://arxiv.org/pdf/1606.00704.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Dumoulin, V., Belghazi, I., Poole, B., Lamb, A., Arjovsky, M., Mastropietro, O. and Courville, A., 2016. arXiv preprint arXiv:1606.00704.</li> <li><strong>A guide to convolution arithmetic for deep learning</strong> <a href="https://arxiv.org/pdf/1603.07285.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Dumoulin, V. and Visin, F., 2016. arXiv preprint arXiv:1603.07285.</li> <li><strong>Is the deconvolution layer the same as a convolutional layer?</strong> <a href="https://arxiv.org/pdf/1609.07009.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Shi, W., Caballero, J., Theis, L., Huszar, F., Aitken, A., Ledig, C. and Wang, Z., 2016. arXiv preprint arXiv:1609.07009.</li> <li><strong>Conditional generative adversarial nets for convolutional face generation</strong> <a href="http://www.foldl.me/uploads/papers/tr-cgans.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Gauthier, J., 2014. Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter semester, Vol 2014.</li> <li><strong>Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network</strong> <a href="https://arxiv.org/pdf/1609.05158.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Shi, W., Caballero, J., Huszar, F., Totz, J., Aitken, A.P., Bishop, R., Rueckert, D. and Wang, Z., 2016. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1874—1883. <a href="https://doi.org/10.1109/cvpr.2016.207" target="_blank" rel="noopener noreferrer">DOI: 10.1109/cvpr.2016.207<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><strong>Image super-resolution using deep convolutional networks</strong> <a href="https://arxiv.org/pdf/1501.00092.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Dong, C., Loy, C.C., He, K. and Tang, X., 2014. arXiv preprint arXiv:1501.00092.</li> <li><strong>Perceptual losses for real-time style transfer and super-resolution</strong> <a href="https://arxiv.org/pdf/1603.08155.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Johnson, J., Alahi, A. and Fei-Fei, L., 2016. arXiv preprint arXiv:1603.08155.</li> <li><strong>Inceptionism: Going deeper into neural networks</strong> <a href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" target="_blank" rel="noopener noreferrer">[HTML]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Mordvintsev, A., Olah, C. and Tyka, M., 2015. Google Research Blog. Retrieved June, Vol 20.</li> <li><strong>Geodesics of learned representations</strong> <a href="https://arxiv.org/pdf/1511.06394.pdf" target="_blank" rel="noopener noreferrer">[PDF]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Henaff, O.J. and Simoncelli, E.P., 2015. arXiv preprint arXiv:1511.06394.</li> <li><strong>DeepDreaming with TensorFlow</strong> <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb" target="_blank" rel="noopener noreferrer">[link]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>
Mordvintsev, A., 2016.</li></ol></div></div> <div class="page-edit"><!----> <div class="tags"><a href="/tags/?tag=Deconvolution" title="标签">#Deconvolution</a><a href="/tags/?tag=Paper" title="标签">#Paper</a><a href="/tags/?tag=DeepLearning" title="标签">#DeepLearning</a></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">a minute ago</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/8713ed/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">神经网络算法解析</div></a> <!----></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/8713ed/" class="prev">神经网络算法解析</a></span> <!----></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/8713ed/"><div>神经网络算法解析</div></a> <span>08-28</span></dt></dl><dl><dd>02</dd> <dt><a href="/development/git/"><div>线性规划算法</div></a> <span>08-14</span></dt></dl><dl><dd>03</dd> <dt><a href="/courses/algorithm/dynamic-programming/"><div>动态规划</div></a> <span>06-14</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div> </main></div> <div class="footer"><div class="icons"><a href="mailto:434596665@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://music.163.com/#/user/home?id=304537395" title="听音乐" target="_blank" class="iconfont icon-erji"></a><a href="https://github.com/PommesPeter" title="GitHub" target="_blank" class="iconfont icon-github"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2021-2021 
    <span><a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank">Evan Xu</a> | <a href="https://github.com/xugaoyi/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a></span> <p>
      本网站已在灾难中运行:  
    </p></div> <div class="buttons"><!----> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">跟随系统</li><li class="iconfont icon-rijianmoshi">浅色模式</li><li class="iconfont icon-yejianmoshi">深色模式</li><li class="iconfont icon-yuedu">阅读模式</li></ul></div></div> <div class="body-bg" style="background:url() center center / cover no-repeat;opacity:0.5;"></div></div><div class="global-ui"><div id="live2d-widget" class="live2d-widget-container" style="position:fixed;right:65px;bottom:0px;width:135px;height:300px;z-index:99999;opacity:0.95;pointer-events:none;"><canvas id="live2d_canvas" width="135" height="300" class="live2d_canvas" style="position:absolute;left:0px;top:0px;width:135px;height:300px;"></canvas></div></div></div>
    <script src="/assets/js/app.b6cd2856.js" defer></script><script src="/assets/js/6.046822e7.js" defer></script><script src="/assets/js/7.732bae66.js" defer></script><script src="/assets/js/8.8f95e629.js" defer></script>
  </body>
</html>