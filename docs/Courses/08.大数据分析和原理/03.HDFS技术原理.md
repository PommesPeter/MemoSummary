---
title: HDFS技术原理
permalink: /courses/bigdata/hdfs
categories:
  - 课程学习
  - 大数据
tags: 
  - BigData
  - Hadoop
  - HDFS
---

# Hadoop技术原理

## 什么是HDFS？

HDFS全称为 Hadoop Distribution File System，与传统的操作系统文件系统类似，但HDFS是针对分布式存储设计文件系统，需要有能够有对分布式存储的支持，所以 HDFS 与传统的文件系统不同在于HDFS能够通过网络通信实现不同机器之间的通信，将多台机器设备连接到一起，将不同机器上的节点连接起来，形成分布式集群来存储相关的文件。

## HDFS工作原理**



### HDFS结构

HDFS主要设计的结构为主从式结构，由一个主服务器来控制旗下所有的从服务器。其中，主服务器一般不做任何存储数据，所有由网络传输过来的数据都会先经过主服务器存储到内存当中，在内存中等待HDFS文件系统将数据分配到各个从服务器上。

> **文件块**：因为如果按照字节来存储数据会导致寻址时间过长的问题，所以在分布式文件系统中所有的都是采用块结构来存储，一个块大概有64MB或者128MB。
>
> 通过不同的文件块来存储文件，能够最大程度减少寻址开销。
>
> 以块的方式存储能够支持存储大规模的文件，同时也简化了系统对文件系统设计，因为直接通过计算文件块就能得出不同节点的块的数量，方便管理数据。以块的方式存储在备份数据的时候具有较快的速度和效率，可以一次性存储到不同的节点。

HDFS结构上主要分为名称节点 ( NameNode ) 和数据节点 ( DataNode ) ，HDFS通过名称节点对数据节点进行相关的操作，客户端只可以访问名称节点，不可以直接访问数据节点，而是由名称节点对数据节点进行操作，分配从客户端上传的数据。下面针对名称节点和数据节点的结构进行介绍：

![image-20210926171713433](src/03.HDFS%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/image-20210926171713433.png)



#### 名称节点

**名称节点 ( NameNode )**：主要存放上传上来的元数据，将元数据保存在内存当中，同时还要保存数据、块和节点之间的映射关系。名称节点记录了每个文件中各个块所在的数据节点的位置信息。

**数据结构：**名称节点主要由 `FsImage`和 `EditLog` 组成，分别用于维护数据和对数据的操作。

- `FsImage`

  FsImage 主要用于维护文件系统中所有存储的文件的文件的树状结构的元数据。简单来说，就是存放了不同数据、数据节点、数据块是对应在哪个机器上的，主要存储的是数据的映射关系，也就是存储数据的数据，这个数据的数据反应数据的存储位置映射关系。FsImage 会将数据加载到内存中，在 EditLog 读取到对应的操作之后，文件系统就会开始执行。存储了文件的复制等级、修改、访问时间、访问权限、块大小以及组成文件的块。目录存储了修改时间、权限和元数据。

-  `EditLog`

  EditLog 是一个日志文件，主要存储了客户端对分布式文件系统的各种操作，只要有数据的创建、删除、修改，就会将对应的操作存入日志文件，后续经过文件系统读取来执行，。在 FsImage 存入内存的时候，同时也会加载 EditLog 里面的内容，执行对应的操作。EditLog 文件在整个 HDFS 运行的周期当中，一定要保持实时更新，但是这里就会导致一个问题，当操作过多时导致 EditLog 文件过大，导致系统启动和运行十分缓慢，下面会说到如何解决这个问题。

**名称节点启动流程**：

1. 名称节点启动之后，会将 FsImage 加载到内存当中，之后执行 EditLog 文件中的各项操作。
2. 启动成功之后，会创建新的 FsImage 和 EditLog 文件。

**解决 EditLog 文件不断变大的问题**：新添加第二名称节点 ( SecondryNameNode)，使用第二名称节点来解决这个问题。第二名称节点会部署到另一台服务器上，第二名称节点会周期性地和 NameNode 进行通信，获得到 NameNode 下的 FsImage 和 EditLog 文件，像 NameNode 一样。将获得的 FsImage 和 EditLog 文件进行处理，加载 FsImage 文件到内存，执行 EditLog 文件上的操作，执行完之后将新的 FsImage 文件发送回 NameNode 上。

在执行上述步骤的同时,NameNode 会创建一个新的 edits.new 文件来继续执行客户端后续的请求，等待第二名称节点将新的 FsImage 文件发送过来之后进行替换，同时也将edits.new 文件替换成 EditLog 文件。

​    ![image-20210926170951687](src/03.HDFS%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/image-20210926170951687.png)



#### 数据节点

- 数据节点是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客户端或者是名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的块的列表

- 每个数据节点中的数据会被保存在各自节点的本地Linux文件系统中

## HDFS存储原理**

### 冗余数据存储

针对一个文件系统，为了保证系统的容错性和可用性，HDFS 采用多副本的方式进行存储，就是每次从客户端发送的请求往集群当中添加数据，**都会将该数据复制两份，一份放到同一台设备上不同的数据节点，另一份放到不同设备上的数据节点，原来上传的数据则选择一台磁盘不满、CPU不忙的设备上写入**。如果是集群内进行的写入操作，则会将副本放到就近的数据节点上写入数据。

### 数据存取方法

#### 数据存放

- 第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点

- 第二个副本：放置在与第一个副本不同的机架的节点上

- 第三个副本：与第一个副本相同机架的其他节点上

- 更多副本：随机节点

#### 数据读取

- HDFS提供了一个API可以确定一个数据节点所属的机架ID，客户端也可以调用API获取自己所属的机架ID

- 当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含了副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID，**当发现某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择该副本读取数据，如果没有发现，就随机选择一个副本读取数据。**

### 数据错误、恢复

#### 名称节点出错

名称节点保存了所有的元数据信息，备份一般会读取第二名称节点服务器上的备份，当名称节点出错时，就可以根据备份服务器SecondaryNameNode中的FsImage和Editlog数据进行恢复。

#### 数据节点出错

数据节点会向名称节点定期发送信息，报告自己的状态。

当数据节点发生错误时，文件系统会自动标记这些数据节点为 “宕机” 状态，这个节点上的数据均不可读，名称节点不会发送任何 IO。

名称节点会定期检查这种情况，一旦发现某个数据块的副本数量小于冗余因子，就会启动数据冗余复制，为它生成新的副本。

HDFS 和其它分布式文件系统的最大区别就是可以调整冗余数据的位置。

#### 数据错误

网络传输和磁盘错误等因素，都会造成数据错误。

客户端在读取到数据后，会采用md5和sha1对数据块进行校验，以确定读取到正确的数据。

在文件被创建时，客户端就会对每一个文件块进行信息摘录，并把这些信息写入到同一个路径的隐藏文件里面。

当客户端读取文件的时候，会先读取该信息文件，然后，利用该信息文件对每个读取的数据块进行校验，如果校验出错，客户端就会请求到另外一个数据节点读取该文件块，并且向名称节点报告这个文件块有错误，名称节点会定期检查并且重新复制这个块。

## HDFS数据读写过程

**读数据：**使用文件系统打开文件 $\rarr$ 获取文件输入流同时获取数据块的位置 $\rarr$ 通过`read()`方法读取 $\rarr$ 检查输入流状态是否被关闭 $\rarr$ 若未关闭则再次寻找下一个要读取的数据块 $\rarr$ 读取完毕后关闭输入流 $\rarr$ 读完成

**写数据：**发起操作文件请求 $\rarr$ 在名称节点创建元数据 $\rarr$ 客户端写入数据 $\rarr$ 将客户端数据封装成包通过输出流发送到数据节点并写入数据节点 $\rarr$ 接受完毕后数据节点发送确定包给输出流 $\rarr$ 输出流关闭 $\rarr$ 写完成

